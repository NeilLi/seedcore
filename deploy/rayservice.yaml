apiVersion: ray.io/v1
kind: RayService
metadata:
  name: seedcore-svc
  namespace: seedcore-dev
spec:
  # ===================================================================
  #  Serve Configuration
  # ===================================================================  
  serveConfigV2: |
    http_options:
      host: 0.0.0.0
      port: 8000
      location: HeadOnly

    applications:
      - name: ml_service
        import_path: entrypoints.ml_entrypoint:build_ml_service
        route_prefix: /ml
        deployments:
          - name: MLService
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.2
              num_gpus: 0
              resources: {"head_node": 0.001}

      - name: cognitive
        import_path: entrypoints.cognitive_entrypoint:build_cognitive_app
        route_prefix: /cognitive
        deployments:
          - name: CognitiveService
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.2
              num_gpus: 0
              memory: 2147483648  # 2GB
              resources: {"head_node": 0.001}

      - name: coordinator
        import_path: entrypoints.coordinator_entrypoint:build_coordinator
        route_prefix: /pipeline
        deployments:
          - name: Coordinator
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.2
              num_gpus: 0
              resources: {"head_node": 0.001}

      - name: ops
        import_path: entrypoints.ops_entrypoint:build_ops_app
        route_prefix: /ops
        deployments:
          - name: OpsGateway
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.05
              resources: {"head_node": 0.001}

          - name: EventizerService
            num_replicas: 1
            max_concurrent_queries: 100
            ray_actor_options:
              num_cpus: 0.05
              memory: 2147483648    # 2GB

          - name: FactManager
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.1
              memory: 1073741824    # 1GB

          - name: StateService
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.15
              memory: 1073741824    # 1GB

          - name: EnergyService
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.15
              memory: 1073741824    # 1GB

      - name: organism
        import_path: entrypoints.organism_entrypoint:build_organism_app
        route_prefix: /organism
        deployments:
          - name: OrganismManager
            num_replicas: 1
            ray_actor_options:
              num_cpus: 0.3
              num_gpus: 0
              memory: 2147483648  # 2GB
              resources: {"head_node": 0.001}

  # ===================================================================
  #  Ray Cluster Configuration
  # ===================================================================
  rayClusterConfig:
    rayVersion: "2.33.0"
    # -------------------------------------------------------------------
    #  Head Node Specification
    # -------------------------------------------------------------------
    headGroupSpec:
      # The Ray Operator will automatically create a Service for the head node.
      # It will also create the 'seedcore-svc-serve-svc' based on the serveConfigV2.
      # By setting proxy_location to HeadOnly, the operator correctly configures
      # the serve service to target ONLY the head pod.
      serviceType: ClusterIP
      rayStartParams:
        dashboard-host: "0.0.0.0"
        dashboard-port: "8265"
        ray-client-server-port: "10001"
        num-cpus: "2"

      template:
        spec:
          containers:
          - name: ray-head
            image: seedcore:latest
            imagePullPolicy: IfNotPresent
            envFrom:
            - secretRef: { name: seedcore-env-secret }
            env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: SERVE_SERVICE
              value: "stable"
            - name: DGL_GRAPHBOLT_SKIP
              value: "0"
            - name: RAY_OVERRIDE_RESOURCES
              value: '{"head_node": 1}'
            - name: RAY_NAMESPACE
              value: "seedcore-dev"
            - name: SEEDCORE_NS
              value: "seedcore-dev"
            - name: XGB_STORAGE_PATH
              value: "/app/data/models"
            # ✅ Routing environment variables for coordinator access
            - name: OCPS_DRIFT_THRESHOLD
              value: "0.5"
            - name: COGNITIVE_TIMEOUT_S
              value: "8.0"
            - name: COGNITIVE_MAX_INFLIGHT
              value: "64"
            - name: FAST_PATH_LATENCY_SLO_MS
              value: "1000"
            - name: MAX_PLAN_STEPS
              value: "16"
            - name: DSP_LOG_TO_FILE
              value: "false"
            - name: DSP_LOG_TO_STDOUT
              value: "true"
            - name: DSP_LOG_PATH
              value: "/tmp/azure_openai_usage.log"
            - name: LOG_TO_FILE
              value: "false"
            - name: LOG_TO_STDOUT
              value: "true"
            - name: LOG_LEVEL
              value: "INFO"
            - name: LLM_PROVIDER
              value: "mlservice"
            ports:
              - name: gcs
                containerPort: 6379
              - name: dashboard
                containerPort: 8265
              - name: client
                containerPort: 10001
              # ✅ FIX: Updated the containerPort to match the new httpOptions port.
              - name: serve
                containerPort: 8000
              - name: metrics
                containerPort: 8080
            resources:
              requests:
                cpu: "500m"
                memory: "4Gi"
              limits:
                cpu: "2"
                memory: "8Gi"
            volumeMounts:
              - name: xgb-model-storage
                mountPath: /app/data
              #- name: project-src
              #  mountPath: /app
            # Probes are good practice for production readiness.
            startupProbe:
              exec:
                command: ["bash", "-lc", "wget --tries=1 -T 2 -q -O- http://127.0.0.1:52365/api/local_raylet_healthz | grep -q success"]
              periodSeconds: 5
              timeoutSeconds: 3
              failureThreshold: 72
            readinessProbe:
              exec:
                command: ["bash", "-lc", "wget --tries=1 -T 2 -q -O- http://127.0.0.1:52365/api/local_raylet_healthz | grep -q success"]
              periodSeconds: 5
              timeoutSeconds: 2
              failureThreshold: 3
            livenessProbe:
              exec:
                command: ["bash", "-lc", "wget --tries=1 -T 2 -q -O- http://127.0.0.1:52365/api/local_raylet_healthz | grep -q success"]
              periodSeconds: 5
              timeoutSeconds: 2
              failureThreshold: 120
          volumes:
            - name: xgb-model-storage
              persistentVolumeClaim:
                claimName: xgb-pvc
            #- name: project-src
            #  hostPath:
            #    path: /project
            #    type: Directory

    # -------------------------------------------------------------------
    #  Worker Node Specification
    # -------------------------------------------------------------------
    workerGroupSpecs:
    - groupName: small
      replicas: 1
      rayStartParams:
        num-cpus: "2"
      template:
        spec:
          containers:
          - name: ray-worker
            image: seedcore:latest
            imagePullPolicy: IfNotPresent
            envFrom:
            - secretRef: { name: seedcore-env-secret }
            env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: SERVE_SERVICE
              value: "stable"
            - name: DGL_GRAPHBOLT_SKIP
              value: "0"
            - name: RAY_NAMESPACE
              value: "seedcore-dev"
            - name: SEEDCORE_NS
              value: "seedcore-dev"
            - name: XGB_STORAGE_PATH
              value: "/app/data/models"
            # ✅ Routing environment variables for coordinator access
            - name: OCPS_DRIFT_THRESHOLD
              value: "0.5"
            - name: COGNITIVE_TIMEOUT_S
              value: "8.0"
            - name: COGNITIVE_MAX_INFLIGHT
              value: "64"
            - name: FAST_PATH_LATENCY_SLO_MS
              value: "1000"
            - name: MAX_PLAN_STEPS
              value: "16"
            - name: DSP_LOG_TO_FILE
              value: "false"
            - name: DSP_LOG_TO_STDOUT
              value: "true"
            - name: DSP_LOG_PATH
              value: "/tmp/azure_openai_usage.log"
            - name: LOG_TO_FILE
              value: "false"
            - name: LOG_TO_STDOUT
              value: "true"
            - name: LOG_LEVEL
              value: "INFO"
            - name: LLM_PROVIDER
              value: "mlservice"
            resources:
              requests:
                cpu: "500m"
                memory: "4Gi"
              limits:
                cpu: "2"
                memory: "8Gi"
            volumeMounts:
              - name: xgb-model-storage
                mountPath: /app/data
              #- name: project-src
              #  mountPath: /app
            readinessProbe:
              exec:
                command: ["bash", "-lc", "wget --tries=1 -T 2 -q -O- http://127.0.0.1:52365/api/local_raylet_healthz | grep -q success"]
              periodSeconds: 5
              timeoutSeconds: 2
              failureThreshold: 3
            livenessProbe:
              exec:
                command: ["bash", "-lc", "wget --tries=1 -T 2 -q -O- http://127.0.0.1:52365/api/local_raylet_healthz | grep -q success"]
              periodSeconds: 5
              timeoutSeconds: 2
              failureThreshold: 120
          volumes:
            - name: xgb-model-storage
              persistentVolumeClaim:
                claimName: xgb-pvc
            #- name: project-src
            #  hostPath:
            #    path: /project
            #    type: Directory
