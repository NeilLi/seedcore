#!/usr/bin/env python3
"""
Verify SeedCore architecture end-to-end:

- Ray cluster reachable
- Coordinator actor healthy & organism initialized
- N Dispatchers + M GraphDispatchers present and responsive
- Serve apps 'orchestrator', 'cognitive', 'ml_service' up
- Submit fast-path task (low drift) -> COMPLETED
- Submit escalation task (high drift) -> COMPLETED
- (Optional) Submit graph task via DB function -> COMPLETED
- Pull Coordinator status/metrics snapshot

IMPORTANT: This script has been updated to gracefully handle missing debugging methods
on the deployed OrganismManager. It will check for method availability before calling
them and provide informative logging about what's available vs. what's missing.

RAY SERVE ERROR FIX: This script now uses a whitelist approach to prevent calling
unsupported methods on the OrganismManager deployment, which eliminates the noisy
"Unhandled error ... Tried to call a method ... does not exist" Ray Serve logs.
The SUPPORTED_COORD_METHODS whitelist and call_if_supported() function ensure only
known-good methods are invoked.

ORCHESTRATOR CONNECTIVITY FIXES: This script now includes comprehensive diagnostics
for orchestrator connectivity issues that cause tasks to get stuck in 'queued' status:
- Enhanced submit_via_orchestrator() with detailed logging and error handling
- Orchestrator connectivity testing (status endpoints, task submission)
- Queue worker status checking to identify stuck tasks
- Option to fail fast when orchestrator is unreachable (no DB fallback)
- Detailed diagnosis and fix recommendations for common issues

Run inside a pod with cluster network access (or locally with port-forward).
Prereqs: pip install requests psycopg2-binary (if DB checks enabled)

Env:
  RAY_ADDRESS=ray://seedcore-svc-head-svc:10001
  RAY_NAMESPACE=seedcore-dev
  SEEDCORE_PG_DSN=postgresql://postgres:postgres@postgresql:5432/seedcore

  ORCH_URL=http://seedcore-api.seedcore-dev.svc.cluster.local:8002  (or http://127.0.0.1:8002)
  ORCH_PATHS=/api/v1/tasks                                   (comma-separated candidate endpoints)

  OCPS_DRIFT_THRESHOLD=0.5
  COGNITIVE_TIMEOUT_S=8.0
  COGNITIVE_MAX_INFLIGHT=64
  FAST_PATH_LATENCY_SLO_MS=1000
  MAX_PLAN_STEPS=16

  EXPECT_DISPATCHERS=2
  EXPECT_GRAPH_DISPATCHERS=1
  VERIFY_GRAPH_TASK=true|false
  DEBUG_ROUTING=true|false          # Enable comprehensive routing debugging
  DEBUG_LEVEL=INFO|DEBUG           # Set logging level for debugging
  STRICT_MODE=true|false           # Exit on validation failures (default: true)
  ENABLE_MOCK_ROUTING_TESTS=false # Enable mock routing tests (default: false)
  ENABLE_DIRECT_FALLBACK=false    # Enable direct execution fallback when orchestrator is down (default: false)
  
  # To completely avoid any debug calls that might cause Ray Serve errors:
  # DEBUG_ROUTING=false

Usage:
  python verify_seedcore_architecture.py           # Run full verification
  python verify_seedcore_architecture.py --debug   # Run only routing debugging
  python verify_seedcore_architecture.py --strict  # Exit on validation failures
  python verify_seedcore_architecture.py --help    # Show this help
"""

import os
import time
import json
import uuid
import logging
import ast
import sys
import argparse
import asyncio
from typing import Any, Dict, Optional, Tuple, List

# Import the new centralized result schema for validation (optional)
try:
    from src.seedcore.models.result_schema import (
        TaskResult, ResultKind, from_legacy_result
    )
    HAS_RESULT_SCHEMA = True
except ImportError:
    HAS_RESULT_SCHEMA = False

# ---- Helper functions for result normalization
def _maybe_parse(x):
    if isinstance(x, str):
        s = x.strip()
        # try JSON first
        try:
            return json.loads(s)
        except Exception:
            pass
        # then safe Python literal (legacy)
        try:
            return ast.literal_eval(s)
        except Exception:
            return x
    return x

def _is_plan_like(items):
    """Returns True if the list looks like HGNN plan steps."""
    if not isinstance(items, list):
        return False
    
    # Only assume HGNN if multi-step or explicit planner marks
    if len(items) > 1:
        for it in items:
            if isinstance(it, dict) and ("organ_id" in it or "solution_steps" in it):
                return True
    
    # For single items, require explicit HGNN indicators
    if len(items) == 1:
        item = items[0]
        if isinstance(item, dict):
            # Check for explicit HGNN markers
            if (item.get("plan_source") == "cognitive_core" or 
                "solution_steps" in item or 
                item.get("kind") == "escalated"):
                return True
            # Don't assume single organ_id means HGNN - could be fast path
            return False
    
    return False

def detect_plan(res: dict) -> Tuple[bool, List]:
    """
    Consolidated helper to detect HGNN plan indicators in a result.
    
    Returns:
        Tuple[bool, List]: (has_plan, plan_steps)
        - has_plan: True if any HGNN indicators are present
        - plan_steps: The actual plan list if found, empty list otherwise
    """
    if not isinstance(res, dict):
        return False, []
    
    # Check for new centralized schema format first - prefer explicit signals
    if res.get("kind") in ["escalated", "cognitive"] and "payload" in res:
        payload = res["payload"]
        if "solution_steps" in payload:
            plan_steps = payload["solution_steps"]
            if isinstance(plan_steps, list) and len(plan_steps) > 0:
                return True, plan_steps
        
        # Check nested result structure for cognitive results
        if res.get("kind") == "cognitive" and "result" in payload:
            nested_result = payload["result"]
            if isinstance(nested_result, dict) and "solution_steps" in nested_result:
                plan_steps = nested_result["solution_steps"]
                if isinstance(plan_steps, list) and len(plan_steps) > 0:
                    return True, plan_steps
    
    # Check for explicit escalated flag
    if res.get("escalated") is True:
        return True, []
    
    # Check for legacy format indicators
    plan = res.get("plan") or res.get("solution_steps")
    if plan and isinstance(plan, list) and len(plan) > 0:
        return True, plan
    
    # Check for list_result type with plan-like content - use updated logic
    if res.get("type") == "list_result":
        items = res.get("items", [])
        if _is_plan_like(items):
            return True, items
    
    # Check for legacy raw_result
    if "raw_result" in res:
        raw = res["raw_result"]
        try:
            parsed = ast.literal_eval(raw)
            if isinstance(parsed, list) and _is_plan_like(parsed):
                return True, parsed
            elif isinstance(parsed, dict) and "solution_steps" in parsed:
                plan_steps = parsed["solution_steps"]
                if isinstance(plan_steps, list) and len(plan_steps) > 0:
                    return True, plan_steps
        except Exception:
            pass
    
    return False, []

# ---- safe env readers
def env(k: str, default: str = "") -> str:
    return os.getenv(k, default)

def env_int(k: str, d: int) -> int:
    try:
        return int(env(k, str(d)))
    except ValueError:
        return d

def env_float(k: str, d: float) -> float:
    try:
        return float(env(k, str(d)))
    except ValueError:
        return d

def env_bool(k: str, d: bool=False) -> bool:
    return env(k, str(d)).lower() in ("1","true","yes","on")

# ---- logging setup (after env functions are defined)
debug_level = env("DEBUG_LEVEL", "INFO").upper()
log_level = logging.DEBUG if debug_level == "DEBUG" else logging.INFO
logging.basicConfig(level=log_level, format="%(asctime)s %(levelname)s %(message)s")
log = logging.getLogger("verify-seedcore")

# Log import status
if HAS_RESULT_SCHEMA:
    log.info("‚úÖ Result schema module imported successfully")
else:
    log.warning("‚ö†Ô∏è Result schema module not available, using fallback validation")

log.info(f"üîß Log level set to: {debug_level}")

# ---- Strict mode control
def should_exit_on_failure() -> bool:
    """Determine if script should exit on validation failures."""
    return STRICT_MODE_ENABLED

def exit_if_strict(message: str, exit_code: int = 1):
    """Exit with message if strict mode is enabled, otherwise log error."""
    if should_exit_on_failure():
        log.error(f"‚ùå {message}")
        sys.exit(exit_code)
    else:
        log.error(f"‚ùå {message} (continuing due to non-strict mode)")

# Global strict mode flag (can be overridden by command line)
STRICT_MODE_ENABLED = True

# ---- HTTP helpers (requests optional)
def _requests():
    try:
        import requests  # type: ignore
        return requests
    except Exception:
        return None

def http_post(url: str, json_body: Dict[str, Any], timeout: float = 8.0) -> Tuple[int, str, Optional[Dict[str, Any]]]:
    req = _requests()
    if not req:
        raise RuntimeError("requests not installed; pip install requests")
    try:
        resp = req.post(url, json=json_body, timeout=timeout)
        txt = resp.text
        try:
            js = resp.json()
        except Exception:
            js = None
        return resp.status_code, txt, js
    except Exception as e:
        return 0, str(e), None

def http_get(url: str, timeout: float = 8.0) -> Tuple[int, str, Optional[Dict[str, Any]]]:
    req = _requests()
    if not req:
        raise RuntimeError("requests not installed; pip install requests")
    try:
        resp = req.get(url, timeout=timeout)
        txt = resp.text
        try:
            js = resp.json()
        except Exception:
            js = None
        return resp.status_code, txt, js
    except Exception as e:
        return 0, str(e), None

# ---- Result normalization helper
def normalize_result(result) -> dict:
    """Normalize task result to ensure it's a Python dict."""
    if result is None:
        return {}

    if isinstance(result, dict):
        return result

    if isinstance(result, str):
        # raw JSON / legacy-printed list/dict
        try:
            return json.loads(result)
        except Exception:
            parsed = _maybe_parse(result)
            if isinstance(parsed, dict):
                return parsed
            if isinstance(parsed, list):
                items = [_maybe_parse(x) for x in parsed]
                return {
                    "type": "list_result",
                    "items": items,
                    "count": len(items),
                    "escalated": _is_plan_like(items),
                }
            # fallback
            return {"type": "unknown_result", "value": result, "original_type": "str"}

    if isinstance(result, list):
        items = [_maybe_parse(x) for x in result]
        return {
            "type": "list_result",
            "items": items,
            "count": len(items),
            "escalated": _is_plan_like(items),
        }

    # Handle other types (Ray ObjectRef, Pydantic models, etc.)
    try:
        if hasattr(result, "model_dump"):
            return result.model_dump()
        if hasattr(result, "dict"):
            return result.dict()
        if hasattr(result, "__dict__"):
            return dict(result.__dict__)
    except Exception:
        pass

    return {
        "type": "unknown_result",
        "value": str(result),
        "original_type": str(type(result)),
    }

# ---- DB helpers (optional)
def pg_conn():
    dsn = env("SEEDCORE_PG_DSN")
    if not dsn:
        return None
    try:
        import psycopg2  # type: ignore
        import psycopg2.extras  # type: ignore
    except Exception:
        log.warning("psycopg2-binary not installed; DB checks disabled")
        return None
    try:
        conn = psycopg2.connect(dsn)
        conn.autocommit = True
        return conn
    except Exception as e:
        log.warning(f"PG connect failed: {e}")
        return None

def pg_get_task(conn, task_id: uuid.UUID) -> Optional[Dict[str, Any]]:
    import psycopg2.extras  # type: ignore
    with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
        cur.execute("SELECT * FROM tasks WHERE id=%s", (str(task_id),))
        row = cur.fetchone()
        return dict(row) if row else None

def pg_wait_status(conn, task_id: uuid.UUID, want: str, timeout_s: float = 60.0) -> Optional[Dict[str, Any]]:
    deadline = time.time() + timeout_s
    last = None
    while time.time() < deadline:
        row = pg_get_task(conn, task_id)
        if row:
            last = row
            st = (row.get("status") or "").lower()
            if st == want.lower():
                return row
        time.sleep(1.0)
    return last

def pg_insert_generic_task(conn, ttype: str, description: str, params: Dict[str, Any], drift: float) -> uuid.UUID:
    import psycopg2.extras  # type: ignore
    tid = uuid.uuid4()
    now_sql = "NOW()"
    with conn.cursor() as cur:
        cur.execute(
            """
            INSERT INTO tasks (id, type, description, params, domain, drift_score, status, attempts, created_at, updated_at)
            VALUES (%s, %s, %s, %s::jsonb, NULL, %s, 'queued', 0, {now}, {now})
            """.format(now=now_sql),
            (str(tid), ttype, description, json.dumps(params), drift),
        )
    return tid

def pg_create_graph_rag_task(conn, node_ids: List[int], hops: int, topk: int, description: str) -> Optional[uuid.UUID]:
    # Requires migrations that define create_graph_rag_task(...)
    tid = None
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT create_graph_rag_task(%s::int[], %s::int, %s::int, %s);",
                        (node_ids, hops, topk, description))
            row = cur.fetchone()
            # The function may return VOID; if it returns id, adapt here.
            tid = None
    except Exception as e:
        log.warning(f"create_graph_rag_task call failed: {e}")
    return tid

# ---- Ray helpers
def ray_connect():
    import ray  # type: ignore
    addr = env("RAY_ADDRESS", "ray://seedcore-svc-head-svc:10001")
    ns = env("RAY_NAMESPACE", env("SEEDCORE_NS", "seedcore-dev"))
    log.info(f"Connecting to Ray: {addr} ns={ns}")
    ray.init(address=addr, namespace=ns, log_to_driver=False, ignore_reinit_error=True)
    return ray

def get_actor(ray, name: str) -> Optional[Any]:
    try:
        return ray.get_actor(name, namespace=env("RAY_NAMESPACE", "seedcore-dev"))
    except Exception:
        return None

def actor_ping(ray, handle, timeout=5.0) -> bool:
    try:
        ref = handle.ping.remote()
        return ray.get(ref, timeout=timeout) == "pong"
    except Exception:
        return False

def actor_status(ray, handle, timeout=10.0) -> Dict[str, Any]:
    try:
        ref = handle.get_status.remote()
    except Exception:
        return {}
    try:
        return ray.get(ref, timeout=timeout)
    except Exception:
        return {}

def serve_get_handle(ray, app_name: str):
    try:
        from ray import serve  # type: ignore
        return serve.get_app_handle(app_name)
    except Exception as e:
        log.warning(f"Serve handle for '{app_name}' not available: {e}")
        return None

def serve_deployment_status(handle, timeout=10.0) -> Dict[str, Any]:
    """Get status from a Serve deployment handle."""
    try:
        import asyncio
        result = asyncio.run(handle.status.remote())
        return result
    except Exception:
        return {}

# ---- Orchestrator client
def submit_via_orchestrator(task: Dict[str, Any]) -> Optional[uuid.UUID]:
    base = env("ORCH_URL", "")
    if not base:
        log.warning("‚ö†Ô∏è ORCH_URL not set - orchestrator submission disabled")
        return None
    
    paths = [p.strip() for p in env("ORCH_PATHS", "/tasks,/ask").split(",") if p.strip()]
    if not paths:
        log.warning("‚ö†Ô∏è ORCH_PATHS not set - orchestrator submission disabled")
        return None
    
    log.info(f"üöÄ Submitting task to orchestrator: {base} with paths {paths}")
    log.info(f"üìã Task payload: {json.dumps(task, default=str)}")
    
    for p in paths:
        url = base.rstrip("/") + p
        try:
            log.info(f"üîó Attempting POST to: {url}")
            code, txt, js = http_post(url, task, timeout=8.0)
            log.info(f"üì° Response: {code} - {txt[:200]}")
            
            if code >= 200 and code < 300:
                log.info(f"‚úÖ Success! Response: {js}")
                # Accept multiple response formats:
                # 1. {"task_id": "..."} (legacy format)
                # 2. {"id": "..."} (current TaskRead format)
                # 3. Plain UUID string
                if isinstance(js, dict):
                    # Try task_id first (legacy)
                    if "task_id" in js:
                        try:
                            task_id = uuid.UUID(str(js["task_id"]))
                            log.info(f"üéØ Extracted task_id from dict: {task_id}")
                            return task_id
                        except Exception as e:
                            log.warning(f"‚ö†Ô∏è Failed to parse task_id from dict: {e}")
                            continue
                    # Try id (current TaskRead format)
                    elif "id" in js:
                        try:
                            task_id = uuid.UUID(str(js["id"]))
                            log.info(f"üéØ Extracted id from dict: {task_id}")
                            return task_id
                        except Exception as e:
                            log.warning(f"‚ö†Ô∏è Failed to parse id from dict: {e}")
                            continue
                    else:
                        log.warning(f"‚ö†Ô∏è Response dict missing both 'task_id' and 'id' fields: {list(js.keys())}")
                        continue
                # fallback: parse UUID from text
                try:
                    task_id = uuid.UUID(str(js))
                    log.info(f"üéØ Extracted task_id from text: {task_id}")
                    return task_id
                except Exception as e:
                    log.warning(f"‚ö†Ô∏è Failed to parse task_id from text: {e}")
                    continue
            else:
                log.warning(f"‚ö†Ô∏è HTTP {code} from {url}: {txt[:200]}")
        except Exception as e:
            log.error(f"‚ùå Exception posting to {url}: {e}")
            continue
    
    log.error(f"‚ùå All orchestrator endpoints failed for task: {task['type']}")
    return None

# ---- Enhanced debugging functions for routing bug investigation

# --- Put near your other helpers in verify_seedcore_architecture.py ---

SUPPORTED_COORD_METHODS = {
    "health",
    "status",
    "get_organism_status",
    "get_organism_summary",
    "handle_incoming_task",
    "handle_task",
    "initialize_organism",
    "make_decision",
    "plan_task",
    "reconfigure",
    "shutdown_organism",
    "test_routing",
}

def serve_can_call(method_name: str) -> bool:
    return method_name in SUPPORTED_COORD_METHODS

def call_if_supported(coord, method_name: str, *args, **kwargs):
    """Never invokes replica for unsupported methods (prevents noisy Ray logs)."""
    if not serve_can_call(method_name):
        log.info(f"üìã Coordinator does not support '{method_name}' (skipping)")
        return None
    try:
        method = getattr(coord, method_name)          # This is safe (client-side proxy)
        return asyncio.run(method.remote(*args, **kwargs))  # Only call if whitelisted
    except Exception as e:
        log.warning(f"‚ö†Ô∏è Call '{method_name}' failed: {e}")
        return None

def inspect_coordinator_routing_logic(ray, coord):
    """Inspect coordinator's routing logic and configuration to identify routing bugs."""
    log.info("üîç INSPECTING COORDINATOR ROUTING LOGIC")
    log.info("=" * 50)

    # Always safe
    st = serve_deployment_status(coord)
    log.info(f"üìã Coordinator status: {json.dumps(st, indent=2, default=str)}")

    # Only supported calls
    s = call_if_supported(coord, "get_organism_status")
    if s is not None:
        log.info(f"üìã get_organism_status: {json.dumps(s, indent=2, default=str)}")

    g = call_if_supported(coord, "get_organism_summary")
    if g is not None:
        log.info(f"üìã get_organism_summary: {json.dumps(g, indent=2, default=str)}")

    log.info("=" * 50)

def check_organ_availability(ray):
    """Check the health and availability of fast-path organs."""
    log.info("üîç CHECKING ORGAN AVAILABILITY")
    log.info("=" * 50)
    
    try:
        # Check dispatcher actors (fast-path organs)
        dispatcher_status = {}
        for i in range(10):  # Check up to 10 dispatchers
            actor_name = f"seedcore_dispatcher_{i}"
            handle = get_actor(ray, actor_name)
            if handle:
                if actor_ping(ray, handle):
                    status = actor_status(ray, handle)
                    dispatcher_status[actor_name] = status
                else:
                    dispatcher_status[actor_name] = {"status": "unresponsive"}
            else:
                break  # No more dispatchers
        
        log.info(f"üìã Found {len(dispatcher_status)} dispatchers:")
        for name, status in dispatcher_status.items():
            health = status.get('status', 'unknown')
            log.info(f"   {name}: {health}")
            
            # Check if dispatcher has organ info
            if hasattr(handle, 'get_organ_info'):
                try:
                    organ_info = ray.get(handle.get_organ_info.remote(), timeout=5.0)
                    log.info(f"      Organ info: {organ_info}")
                except Exception as e:
                    log.debug(f"      Could not get organ info: {e}")
            else:
                log.debug(f"      Dispatcher {name} has no get_organ_info() method")
        
        # Check if any dispatchers are unhealthy
        unhealthy_dispatchers = [name for name, status in dispatcher_status.items() 
                               if status.get('status') != 'healthy']
        
        if unhealthy_dispatchers:
            log.warning(f"‚ö†Ô∏è UNHEALTHY DISPATCHERS: {unhealthy_dispatchers}")
            log.warning("This could force escalation even for low-drift tasks!")
        else:
            log.info("‚úÖ All dispatchers appear healthy")
            
    except Exception as e:
        log.error(f"‚ùå Organ availability check failed: {e}")
    
    log.info("=" * 50)

def check_coordinator_internal_state(ray, coord):
    """Check coordinator's internal state to understand routing decisions."""
    log.info("üîç CHECKING COORDINATOR INTERNAL STATE")
    log.info("=" * 50)

    # Only safe methods; skip the rest entirely
    s = call_if_supported(coord, "get_organism_status")
    if s is not None:
        log.info(f"üìã organism_status: {json.dumps(s, indent=2, default=str)}")

    g = call_if_supported(coord, "get_organism_summary")
    if g is not None:
        log.info(f"üìã organism_summary: {json.dumps(g, indent=2, default=str)}")

    log.info("=" * 50)

def check_coordinator_capabilities(ray, coord):
    """Check if coordinator has the expected routing methods for debugging."""
    log.info("üîç CHECKING COORDINATOR CAPABILITIES")
    log.info("=" * 50)

    # Report only what we'll actually call
    available = sorted(list(SUPPORTED_COORD_METHODS))
    log.info(f"üìã Supported methods (whitelist): {available}")

    # Basic health checks via whitelisted calls
    h = call_if_supported(coord, "health")
    if isinstance(h, dict):
        log.info(f"‚úÖ health: {h}")
    else:
        log.warning("‚ö†Ô∏è health() not available or failed")

    s = call_if_supported(coord, "status")
    if isinstance(s, dict):
        log.info(f"‚úÖ status: {json.dumps(s, indent=2, default=str)}")
    else:
        log.warning("‚ö†Ô∏è status() not available or failed")

    log.info("=" * 50)

def verify_environment_configuration():
    """Verify that environment variables are set correctly."""
    log.info("üîç VERIFYING ENVIRONMENT CONFIGURATION")
    log.info("=" * 50)
    
    # Check critical routing configuration
    drift_threshold = env('OCPS_DRIFT_THRESHOLD', 'NOT_SET')
    log.info(f"üìã OCPS_DRIFT_THRESHOLD: {drift_threshold}")
    
    if drift_threshold == 'NOT_SET':
        log.error("‚ùå OCPS_DRIFT_THRESHOLD not set! This will cause routing issues!")
    else:
        try:
            threshold_value = float(drift_threshold)
            log.info(f"‚úÖ OCPS_DRIFT_THRESHOLD parsed as: {threshold_value}")
            
            # Check if it's reasonable
            if threshold_value <= 0:
                log.error("‚ùå OCPS_DRIFT_THRESHOLD must be positive!")
            elif threshold_value > 1.0:
                log.warning("‚ö†Ô∏è OCPS_DRIFT_THRESHOLD > 1.0 (unusually high)")
            else:
                log.info("‚úÖ OCPS_DRIFT_THRESHOLD value looks reasonable")
        except ValueError:
            log.error(f"‚ùå OCPS_DRIFT_THRESHOLD '{drift_threshold}' is not a valid number!")
    
    # Check other routing-related config
    cognitive_timeout = env('COGNITIVE_TIMEOUT_S', 'NOT_SET')
    log.info(f"üìã COGNITIVE_TIMEOUT_S: {cognitive_timeout}")
    
    fast_path_latency = env('FAST_PATH_LATENCY_SLO_MS', 'NOT_SET')
    log.info(f"üìã FAST_PATH_LATENCY_SLO_MS: {fast_path_latency}")
    
    # Check Ray configuration
    ray_address = env('RAY_ADDRESS', 'NOT_SET')
    ray_namespace = env('RAY_NAMESPACE', 'NOT_SET')
    log.info(f"üìã RAY_ADDRESS: {ray_address}")
    log.info(f"üìã RAY_NAMESPACE: {ray_namespace}")
    
    # Check orchestrator configuration
    orch_url = env('ORCH_URL', 'NOT_SET')
    orch_paths = env('ORCH_PATHS', 'NOT_SET')
    log.info(f"üìã ORCH_URL: {orch_url}")
    log.info(f"üìã ORCH_PATHS: {orch_paths}")
    
    # Test orchestrator connectivity
    test_orchestrator_connectivity()
    
    log.info("=" * 50)

def test_orchestrator_connectivity():
    """Test connectivity to the orchestrator service."""
    log.info("üîç TESTING ORCHESTRATOR CONNECTIVITY")
    log.info("=" * 50)
    
    orch_url = env("ORCH_URL", "")
    if not orch_url:
        log.warning("‚ö†Ô∏è ORCH_URL not set - skipping connectivity test")
        return
    
    # Test basic connectivity
    try:
        import requests
        from urllib.parse import urljoin
        
        # Test status endpoint
        status_url = urljoin(orch_url, "/status")
        log.info(f"üîó Testing status endpoint: {status_url}")
        
        response = requests.get(status_url, timeout=5.0)
        log.info(f"üì° Status endpoint response: {response.status_code}")
        if response.status_code == 200:
            log.info("‚úÖ Status endpoint accessible")
        else:
            log.warning(f"‚ö†Ô∏è Status endpoint returned {response.status_code}")
            
    except ImportError:
        log.warning("‚ö†Ô∏è requests module not available - using http_post helper")
        # Use the existing http_post helper
        status_url = orch_url.rstrip("/") + "/status"
        code, txt, js = http_post(status_url, {}, timeout=5.0)
        log.info(f"üì° Status endpoint response: {code}")
        if code == 200:
            log.info("‚úÖ Status endpoint accessible")
        else:
            log.warning(f"‚ö†Ô∏è Status endpoint returned {code}")
            
    except Exception as e:
        log.error(f"‚ùå Failed to test orchestrator connectivity: {e}")
    
    # Test task submission endpoint
    orch_paths = env("ORCH_PATHS", "/api/v1/tasks")
    for path in orch_paths.split(","):
        path = path.strip()
        if not path:
            continue
            
        test_url = orch_url.rstrip("/") + path
        log.info(f"üîó Testing task endpoint: {test_url}")
        
        # Test with a simple ping task
        test_payload = {"type": "ping", "description": "connectivity test"}
        code, txt, js = http_post(test_url, test_payload, timeout=5.0)
        
        if code >= 200 and code < 300:
            log.info(f"‚úÖ Task endpoint {path} accessible (HTTP {code})")
            if isinstance(js, dict):
                if "task_id" in js:
                    log.info(f"üéØ Received task_id: {js['task_id']}")
                elif "id" in js:
                    log.info(f"üéØ Received id: {js['id']}")
                else:
                    log.info(f"üìã Response keys: {list(js.keys())}")
        else:
            log.warning(f"‚ö†Ô∏è Task endpoint {path} returned HTTP {code}: {txt[:100]}")
    
    # Test with actual task types that the system expects
    log.info("üîç TESTING WITH ACTUAL TASK TYPES")
    test_tasks = [
        {
            "type": "ping",
            "description": "Test connectivity with real task type",
            "params": {"priority": "low"},
            "drift_score": 0.1
        },
        {
            "type": "general_query", 
            "description": "Test escalation task type",
            "params": {"force_decomposition": True},
            "drift_score": 0.8
        }
    ]
    
    for i, test_task in enumerate(test_tasks):
        log.info(f"üß™ Testing task {i+1}: {test_task['type']} (drift: {test_task['drift_score']})")
        
        # Try each endpoint
        for path in orch_paths.split(","):
            path = path.strip()
            if not path:
                continue
                
            test_url = orch_url.rstrip("/") + path
            code, txt, js = http_post(test_url, test_task, timeout=5.0)
            
            if code >= 200 and code < 300:
                log.info(f"‚úÖ Task {i+1} accepted by {path} (HTTP {code})")
                if isinstance(js, dict):
                    if "task_id" in js:
                        log.info(f"üéØ Received task_id: {js['task_id']}")
                    elif "id" in js:
                        log.info(f"üéØ Received id: {js['id']}")
                    else:
                        log.info(f"üìã Response keys: {list(js.keys())}")
                break
            else:
                log.warning(f"‚ö†Ô∏è Task {i+1} rejected by {path} (HTTP {code}): {txt[:100]}")
        else:
            log.error(f"‚ùå Task {i+1} rejected by all endpoints")
    
    log.info("=" * 50)

def check_queue_worker_status():
    """Check if there are any queue workers processing the tasks table."""
    log.info("üîç CHECKING QUEUE WORKER STATUS")
    log.info("=" * 50)
    
    # Check if we can connect to the database
    conn = None
    try:
        import psycopg2
        pg_dsn = env("SEEDCORE_PG_DSN", "")
        if pg_dsn:
            conn = psycopg2.connect(pg_dsn)
            log.info("‚úÖ Database connection successful")
            
            # Check for active tasks
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT 
                        status, 
                        COUNT(*) as count,
                        MIN(created_at) as oldest,
                        MAX(created_at) as newest,
                        AVG(EXTRACT(EPOCH FROM (updated_at - created_at))) as avg_age_seconds
                    FROM tasks 
                    GROUP BY status
                    ORDER BY status
                """)
                
                rows = cur.fetchall()
                if rows:
                    log.info("üìä Current task status distribution:")
                    for status, count, oldest, newest, avg_age in rows:
                        log.info(f"   {status}: {count} tasks")
                        if oldest and newest:
                            log.info(f"     Oldest: {oldest}")
                            log.info(f"     Newest: {newest}")
                        if avg_age is not None:
                            log.info(f"     Avg age: {avg_age:.1f}s")
                else:
                    log.warning("‚ö†Ô∏è No tasks found in database")
                
                # Check for stuck tasks (queued for too long)
                cur.execute("""
                    SELECT 
                        COUNT(*) as stuck_count,
                        MIN(created_at) as oldest_stuck
                    FROM tasks 
                    WHERE status = 'queued' 
                    AND updated_at = created_at
                    AND attempts = 0
                """)
                
                stuck_count, oldest_stuck = cur.fetchone()
                if stuck_count > 0:
                    log.warning(f"‚ö†Ô∏è Found {stuck_count} stuck tasks (queued, no attempts, no updates)")
                    if oldest_stuck:
                        age_hours = (time.time() - oldest_stuck.timestamp()) / 3600
                        log.warning(f"   Oldest stuck task is {age_hours:.1f} hours old")
                    log.warning("   These tasks will never be processed without a queue worker!")
                else:
                    log.info("‚úÖ No stuck tasks found")
                    
        else:
            log.warning("‚ö†Ô∏è SEEDCORE_PG_DSN not set - cannot check queue status")
            
    except ImportError:
        log.warning("‚ö†Ô∏è psycopg2 not available - cannot check queue status")
    except Exception as e:
        log.error(f"‚ùå Failed to check queue status: {e}")
    finally:
        if conn:
            conn.close()
    
    log.info("=" * 50)

def test_routing_decision_logic():
    """Test the routing decision logic with various drift scores."""
    log.info("üîç TESTING ROUTING DECISION LOGIC")
    log.info("=" * 50)
    
    drift_threshold = env_float('OCPS_DRIFT_THRESHOLD', 0.5)
    log.info(f"üìã Testing with threshold: {drift_threshold}")
    
    # Test cases
    test_cases = [
        (0.1, "Should route to fast-path (below threshold)"),
        (0.3, "Should route to fast-path (below threshold)"),
        (0.49, "Should route to fast-path (just below threshold)"),
        (0.5, "Should escalate (at threshold)"),
        (0.51, "Should escalate (just above threshold)"),
        (0.7, "Should escalate (above threshold)"),
        (0.9, "Should escalate (well above threshold)")
    ]
    
    for drift_score, expected in test_cases:
        should_escalate = drift_score >= drift_threshold
        log.info(f"üìä Drift {drift_score:.2f}: {'ESCALATE' if should_escalate else 'FAST-PATH'} - {expected}")
    
    log.info("=" * 50)

def test_routing_with_mock_tasks(ray, coord):
    """Test routing logic by submitting mock tasks with different drift scores."""
    # Check if mock tests are enabled
    if not env_bool("ENABLE_MOCK_ROUTING_TESTS", False):
        log.info("üîç MOCK ROUTING TESTS DISABLED (set ENABLE_MOCK_ROUTING_TESTS=true to enable)")
        log.info("   This prevents flooding the orchestrator with test tasks in production")
        return
    
    log.info("üîç TESTING ROUTING WITH MOCK TASKS")
    log.info("=" * 50)
    
    try:
        # Test different drift scores to see routing behavior
        test_cases = [
            (0.1, "Very low drift - should definitely go to fast path"),
            (0.3, "Low drift - should go to fast path"),
            (0.49, "Just below threshold - should go to fast path"),
            (0.5, "At threshold - should escalate"),
            (0.51, "Just above threshold - should escalate"),
            (0.7, "High drift - should escalate")
        ]
        
        for drift_score, description in test_cases:
            log.info(f"üß™ Testing drift {drift_score:.2f}: {description}")
            
            # Create mock task
            mock_task = {
                "type": "test_query",
                "description": f"Test task with drift {drift_score}",
                "params": {"test": True, "drift": drift_score},
                "drift_score": drift_score
            }
            
            # Try to submit via coordinator if it has a test method
            if serve_can_call('test_routing'):
                try:
                    result = call_if_supported(coord, 'test_routing', mock_task)
                    if result is not None:
                        log.info(f"   üìã Routing result: {json.dumps(result, indent=2, default=str)}")
                        
                        # Analyze the result
                        if isinstance(result, dict):
                            escalated = result.get('escalated', False)
                            route_type = result.get('route_type', 'unknown')
                            organ_id = result.get('organ_id')
                            
                            expected_escalation = drift_score >= env_float('OCPS_DRIFT_THRESHOLD', 0.5)
                            
                            # Explicit escalation confirmation check
                            if escalated is True:
                                log.info("‚úÖ Escalation confirmed: HGNN decomposition plan")
                                # Check for required escalation metadata
                                plan_source = result.get('plan_source')
                                if plan_source == "cognitive_core":
                                    log.info(f"   ‚úÖ Plan source confirmed: {plan_source}")
                                else:
                                    log.warning(f"   ‚ö†Ô∏è Missing or incorrect plan_source: {plan_source}")
                                
                                step_count = result.get('step_count')
                                if step_count is not None:
                                    log.info(f"   ‚úÖ Step count: {step_count}")
                                else:
                                    log.warning("   ‚ö†Ô∏è Missing step_count in escalation result")
                            else:
                                log.info("‚úÖ Fast path confirmed: direct routing")
                            
                            if escalated == expected_escalation:
                                log.info(f"   ‚úÖ Routing correct: drift {drift_score} -> {'escalated' if escalated else 'fast_path'}")
                            else:
                                log.warning(f"   ‚ö†Ô∏è Routing incorrect: drift {drift_score} -> {'escalated' if escalated else 'fast_path'} (expected {'escalated' if expected_escalation else 'fast_path'})")
                            
                            log.info(f"   üìã Route type: {route_type}, Organ: {organ_id}")
                    else:
                        log.info("   üìã test_routing method not available or failed")
                        
                except Exception as e:
                    log.warning(f"   ‚ö†Ô∏è test_routing method not available or failed: {e}")
            
            # Try to submit via orchestrator if available
            else:
                log.info("   üìã No test_routing method available, skipping mock task test")
                break
            
            # Small delay between tests
            time.sleep(0.5)
            
    except Exception as e:
        log.error(f"‚ùå Mock task routing test failed: {e}")
    
    log.info("=" * 50)

def diagnose_routing_issue():
    """Provide a clear diagnosis of the routing issue based on collected information."""
    log.info("üîç ROUTING ISSUE DIAGNOSIS")
    log.info("=" * 60)
    
    # Check environment configuration
    drift_threshold = env('OCPS_DRIFT_THRESHOLD', 'NOT_SET')
    if drift_threshold == 'NOT_SET':
        log.error("‚ùå ROOT CAUSE: OCPS_DRIFT_THRESHOLD environment variable is not set!")
        log.error("   This will cause the coordinator to use a default value or fail to route correctly.")
        log.error("   SOLUTION: Set OCPS_DRIFT_THRESHOLD=0.5 in your environment.")
        return
    
    try:
        threshold_value = float(drift_threshold)
        log.info(f"üìã Drift threshold: {threshold_value}")
        
        if threshold_value <= 0:
            log.error("‚ùå ROOT CAUSE: OCPS_DRIFT_THRESHOLD is not positive!")
            log.error("   This will cause all tasks to be escalated regardless of drift score.")
            log.error("   SOLUTION: Set OCPS_DRIFT_THRESHOLD to a positive value (e.g., 0.5)")
            return
            
    except ValueError:
        log.error(f"‚ùå ROOT CAUSE: OCPS_DRIFT_THRESHOLD '{drift_threshold}' is not a valid number!")
        log.error("   This will cause parsing errors and incorrect routing decisions.")
        log.error("   SOLUTION: Ensure OCPS_DRIFT_THRESHOLD is a valid number (e.g., 0.5)")
        return
    
    # Check orchestrator connectivity
    orch_url = env('ORCH_URL', 'NOT_SET')
    if orch_url == 'NOT_SET':
        log.error("‚ùå ROOT CAUSE: ORCH_URL environment variable is not set!")
        log.error("   This will cause submit_via_orchestrator() to return None and fall back to DB insertion.")
        log.error("   SOLUTION: Set ORCH_URL to point to your orchestrator service.")
        return
    
    # Check if the issue is likely configuration vs. logic
    log.info("üîç LIKELY ROOT CAUSES:")
    log.info("1. Configuration mismatch between environment and coordinator")
    log.info("2. Organ unavailability forcing escalation fallback")
    log.info("3. Bug in coordinator's routing decision logic")
    log.info("4. Environment variable not being read correctly inside coordinator")
    log.info("5. Orchestrator service unreachable (causing DB fallback to orphaned tasks)")
    log.info("6. No queue workers processing the tasks table")
    
    log.info("üîç SPECIFIC ISSUE ANALYSIS:")
    log.info("The assertion failure occurs because:")
    log.info("- submit_via_orchestrator() failed (returned None)")
    log.info("- pg_insert_generic_task() was called as fallback")
    log.info("- Task was inserted into DB with status='queued'")
    log.info("- No queue workers are processing the tasks table")
    log.info("- Task remains stuck in 'queued' status forever")
    log.info("- wait_for_completion() times out waiting for 'completed' status")
    
    log.info("üîç NEXT STEPS:")
    log.info("1. Check coordinator logs for routing decision details")
    log.info("2. Verify coordinator is reading OCPS_DRIFT_THRESHOLD correctly")
    log.info("3. Check if fast-path organs are healthy and available")
    log.info("4. Look for any forced escalation logic in coordinator code")
    log.info("5. Test orchestrator connectivity: curl -v '$ORCH_URL/status'")
    log.info("6. Check if queue workers are running and processing tasks")
    
    log.info("=" * 60)

def provide_fix_recommendations():
    """Provide specific recommendations for fixing the routing bug."""
    log.info("üîß ROUTING BUG FIX RECOMMENDATIONS")
    log.info("=" * 60)
    
    log.info("üìã ORCHESTRATOR CONNECTIVITY ISSUES:")
    log.info("1. Check ORCH_URL and ORCH_PATHS environment variables")
    log.info("2. Test connectivity: curl -v '$ORCH_URL/status'")
    log.info("3. Test task submission: curl -v -X POST '$ORCH_URL/tasks' -d '{\"type\":\"ping\"}'")
    log.info("4. Verify orchestrator service is running: kubectl get pods -l app=orchestrator")
    log.info("5. Check orchestrator logs: kubectl logs <orchestrator-pod>")
    
    log.info("üìã QUEUE WORKER ISSUES:")
    log.info("1. Check if queue workers are running: kubectl get pods -l app=queue-worker")
    log.info("2. Verify tasks table is being processed: check DB for stuck 'queued' tasks")
    log.info("3. Look for queue worker logs: kubectl logs <queue-worker-pod>")
    log.info("4. Check if tasks are being picked up: monitor attempts and locked_by columns")
    
    log.info("üìã IMMEDIATE ACTIONS:")
    log.info("1. Check coordinator logs for routing decision details")
    log.info("2. Verify OCPS_DRIFT_THRESHOLD is set correctly in coordinator environment")
    log.info("3. Check if fast-path organs are healthy and responding")
    
    log.info("üìã CODE INVESTIGATION:")
    log.info("1. Look at coordinator's route_and_execute method")
    log.info("2. Check the drift score comparison logic (>= vs >)")
    log.info("3. Look for any forced escalation fallback logic")
    log.info("4. Verify environment variable parsing in coordinator initialization")
    
    log.info("üìã COMMON BUG PATTERNS:")
    log.info("1. Threshold comparison inverted: if drift_score >= threshold: escalate()")
    log.info("2. Environment variable not loaded: using default value instead")
    log.info("3. Organ unavailability forcing escalation as fallback")
    log.info("4. String vs float comparison: '0.1' >= '0.5' evaluates to True")
    log.info("5. Orchestrator unreachable causing DB fallback to orphaned tasks")
    log.info("6. No queue workers consuming the tasks table")
    
    log.info("üìã DEBUGGING COMMANDS:")
    log.info("1. Check coordinator environment: kubectl exec -it <coordinator-pod> -- env | grep OCPS")
    log.info("2. Check coordinator logs: kubectl logs <coordinator-pod> | grep -i routing")
    log.info("3. Check organ health: kubectl logs <dispatcher-pod> | grep -i health")
    log.info("4. Test orchestrator: curl -v '$ORCH_URL/status'")
    log.info("5. Check queue status: psql -d seedcore -c \"SELECT status, COUNT(*) FROM tasks GROUP BY status;\"")
    
    log.info("=" * 60)

# ---- scenario steps
def check_cluster_and_actors():
    ray = ray_connect()
    ns = env("RAY_NAMESPACE", "seedcore-dev")

    # Coordinator - now managed by Ray Serve organism app
    try:
        from ray import serve
        coord = serve.get_deployment_handle("OrganismManager", app_name="organism")
        log.info("‚úÖ Found OrganismManager Serve deployment")
        
        # Check health using the Serve deployment
        import asyncio
        try:
            # Try to get health status
            health_result = asyncio.run(coord.health.remote())
            log.info(f"Coordinator health: {health_result}")
            assert health_result.get("status") == "healthy", f"Coordinator unhealthy: {health_result}"
            assert health_result.get("organism_initialized") is True, "Organism not initialized"
        except Exception as e:
            log.warning(f"Could not get health status: {e}")
            # If health check fails, just verify the handle exists
            log.info("Coordinator handle exists, proceeding with verification")
    except Exception as e:
        log.error(f"Failed to get OrganismManager Serve deployment: {e}")
        raise AssertionError("OrganismManager Serve deployment not found")

    # Dispatchers
    want_d = env_int("EXPECT_DISPATCHERS", 2)
    found_d = 0
    for i in range(max(1, want_d)):
        h = get_actor(ray, f"seedcore_dispatcher_{i}")
        if h and actor_ping(ray, h):
            found_d += 1
    assert found_d >= want_d, f"Only {found_d}/{want_d} Dispatchers responsive"

    # GraphDispatchers
    want_g = env_int("EXPECT_GRAPH_DISPATCHERS", 1)
    found_g = 0
    for i in range(max(1, want_g)):
        h = get_actor(ray, f"seedcore_graph_dispatcher_{i}")
        if h and actor_ping(ray, h):
            found_g += 1
    assert found_g >= want_g, f"Only {found_g}/{want_g} GraphDispatchers responsive"

    # Serve apps
    for app in ("orchestrator", "cognitive", "ml_service"):
        handle = serve_get_handle(ray, app)
        assert handle is not None, f"Serve app '{app}' not available"

    log.info("Actors and Serve apps look good.")
    return ray, coord

def wait_for_completion(conn, tid: uuid.UUID, label: str, timeout_s: float = 90.0):
    row = pg_wait_status(conn, tid, "completed", timeout_s)
    assert row, f"{label}: task not found in DB"
    st = (row.get("status") or "").lower()
    assert st == "completed", f"{label}: final status={st}, row={row}"
    assert row.get("result") is not None, f"{label}: missing result"
    log.info(f"{label}: COMPLETED with result keys={list((row['result'] or {}).keys()) if isinstance(row.get('result'), dict) else '‚Ä¶'}")
    return row

def scenario_fast_path(conn) -> uuid.UUID:
    """Low drift ‚Üí fast routing to organ."""
    payload = {
        "type": "general_query",
        "description": "what time is it in UTC?",
        "params": {"priority": "low"},
        "drift_score": min(0.1, env_float("OCPS_DRIFT_THRESHOLD", 0.5) / 2.0),
    }
    
    # Check if direct execution fallback is enabled
    enable_direct_fallback = env_bool("ENABLE_DIRECT_FALLBACK", False)
    
    # Try orchestrator first
    tid = submit_via_orchestrator(payload)
    if tid:
        return tid
    
    if enable_direct_fallback:
        # Fallback: direct execution via Serve (no DB tracking)
        log.warning("‚ö†Ô∏è Orchestrator unavailable; executing via Serve handle (no DB verification).")
        # Note: This would need access to the coordinator handle from the calling context
        # For now, we'll raise an error indicating the orchestrator is needed
        raise RuntimeError("Orchestrator unavailable. Set ENABLE_DIRECT_FALLBACK=true and pass coordinator handle for direct execution.")
    else:
        # Fail fast - no fallback
        raise RuntimeError("Failed to create fast-path task via orchestrator (no DB fallback)")

def scenario_escalation(conn) -> uuid.UUID:
    """High drift ‚Üí escalate to CognitiveCore for planning."""
    payload = {
        "type": "general_query",
        "description": "Plan a multi-step analysis over graph + retrieval + synthesis",
        "params": {"force_decomposition": True},
        "drift_score": max(env_float("OCPS_DRIFT_THRESHOLD", 0.5) + 0.2, 0.9),
    }
    tid = submit_via_orchestrator(payload)
    assert tid, "Failed to create escalation task via orchestrator (no DB fallback)"
    return tid

def scenario_graph_task(conn) -> Optional[uuid.UUID]:
    """Optional: exercise GraphDispatcher via DB function."""
    if not conn:
        return None
    try:
        # If your SQL helper returns an ID, adapt accordingly; otherwise the dispatcher will pick it up anyway.
        _ = pg_create_graph_rag_task(conn, node_ids=[123], hops=2, topk=8, description="Find similar nodes to 123")
        log.info("Submitted graph RAG task via DB function (id may be implicit).")
        return None
    except Exception as e:
        log.warning(f"Graph task submission skipped: {e}")
        return None

def scenario_debug_routing(ray, coord):
    """Debug routing issues by running comprehensive diagnostics."""
    log.info("üîç RUNNING ROUTING DEBUG DIAGNOSTICS")
    log.info("=" * 60)
    
    # Step 1: Check coordinator capabilities
    check_coordinator_capabilities(ray, coord)
    
    # Step 2: Verify environment configuration
    verify_environment_configuration()
    
    # Step 3: Check queue worker status
    check_queue_worker_status()
    
    # Step 4: Test routing decision logic
    test_routing_decision_logic()
    
    # Step 5: Check organ availability
    check_organ_availability(ray)
    
    # Step 6: Inspect coordinator routing logic
    inspect_coordinator_routing_logic(ray, coord)
    
    # Step 7: Check coordinator internal state
    check_coordinator_internal_state(ray, coord)
    
    # Step 8: Test routing with mock tasks
    test_routing_with_mock_tasks(ray, coord)
    
    # Step 9: Provide diagnosis
    diagnose_routing_issue()
    
    # Step 10: Provide fix recommendations
    provide_fix_recommendations()
    
    log.info("=" * 60)
    log.info("üîç ROUTING DEBUG DIAGNOSTICS COMPLETED")
    log.info("=" * 60)

def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Verify SeedCore architecture and debug routing issues",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python verify_seedcore_architecture.py           # Run full verification
  python verify_seedcore_architecture.py --debug   # Run only routing debugging
  python verify_seedcore_architecture.py --strict  # Exit on validation failures
  python verify_seedcore_architecture.py --help    # Show this help
        """
    )
    
    parser.add_argument(
        '--debug', 
        action='store_true',
        help='Run only routing debugging diagnostics (skip full verification)'
    )
    
    parser.add_argument(
        '--debug-level',
        choices=['INFO', 'DEBUG'],
        default='INFO',
        help='Set logging level (default: INFO)'
    )
    
    parser.add_argument(
        '--strict',
        action='store_true',
        help='Exit on validation failures (default: controlled by STRICT_MODE env var)'
    )
    
    return parser.parse_args()

def debug_only_mode(ray, coord):
    """Run only the routing debugging diagnostics."""
    log.info("üîç RUNNING ROUTING DEBUG DIAGNOSTICS ONLY")
    log.info("=" * 60)
    
    # Run comprehensive debugging
    scenario_debug_routing(ray, coord)
    
    log.info("=" * 60)
    log.info("üéØ DEBUGGING COMPLETED - Check output above for routing issues")
    log.info("=" * 60)

def main():
    # Parse command line arguments
    args = parse_arguments()
    
    # Override environment debug level if specified
    if args.debug_level != 'INFO':
        os.environ['DEBUG_LEVEL'] = args.debug_level
    
    # Override strict mode if specified via command line
    global STRICT_MODE_ENABLED
    if args.strict:
        STRICT_MODE_ENABLED = True
        os.environ['STRICT_MODE'] = 'true'
    elif args.strict is False:  # Explicitly set to False
        STRICT_MODE_ENABLED = False
        os.environ['STRICT_MODE'] = 'false'
    
    # DB (optional, but highly recommended for verification)
    conn = pg_conn()
    if not conn:
        log.warning("‚ö†Ô∏è DB unavailable; skipping fast-path and escalation validation")
        log.warning("   Set SEEDCORE_PG_DSN environment variable for full verification")

    # Cluster & actors up?
    ray, coord = check_cluster_and_actors()

    # Check if running in debug-only mode
    if args.debug:
        debug_only_mode(ray, coord)
        return

    # DEBUG: Run comprehensive routing diagnostics
    if env_bool("DEBUG_ROUTING", True):
        scenario_debug_routing(ray, coord)

    # Fast path
    fast_tid = scenario_fast_path(conn)
    log.info(f"Fast path task_id = {fast_tid}")
    fast_path_has_plan = False  # Track for summary
    if conn:
        row = wait_for_completion(conn, fast_tid, "FAST-PATH", timeout_s=90.0)
        
        # --- FAST PATH VALIDATION ---
        # Debug: inspect the database row structure
        log.info(f"üìã Fast path row keys: {list(row.keys())}")
        log.info(f"üìã Fast path result column type: {type(row.get('result'))}")
        
        # Normalize result: ensure it's a dict
        raw_res = row.get("result")
        log.info(f"üìã Raw fast path result type: {type(raw_res)}")
        
        res = normalize_result(raw_res)
        if isinstance(res, dict):
            # Log drift score and routing info to understand routing decision
            drift_score = row.get("drift_score")
            log.info(f"üìã Fast path drift_score: {drift_score}")
            log.info(f"üìã Expected drift threshold: {env_float('OCPS_DRIFT_THRESHOLD', 0.5)}")
            
            # Check if drift score should have triggered fast path
            threshold = env_float('OCPS_DRIFT_THRESHOLD', 0.5)
            if drift_score < threshold:
                log.info(f"‚úÖ Drift score {drift_score} < {threshold} - should route to fast path")
            else:
                log.warning(f"‚ö†Ô∏è Drift score {drift_score} >= {threshold} - escalation expected")
                log.warning("   This suggests the task should have been escalated, not routed to fast path")
            
            # Use consolidated plan detection helper
            has_plan, plan_steps = detect_plan(res)
            fast_path_has_plan = has_plan  # Track for summary
            
            if has_plan:
                log.warning("‚ö†Ô∏è Fast path unexpectedly contains HGNN plan indicators (should be direct routing)")
                log.warning("üîç ROUTING BUG DETECTED: Low-drift task was escalated!")
                log.warning("This suggests a bug in the coordinator's routing logic")
                
                # Additional debugging info
                if res.get("type") == "list_result":
                    log.warning("üîç Task was processed as list_result (HGNN plan format)")
                    log.warning("üîç This indicates the coordinator chose escalation path")
                if res.get("escalated"):
                    log.warning("üîç Task explicitly marked as escalated")
                
                # Log the actual result structure for debugging
                log.warning("üîç Full result structure for debugging:")
                log.warning(f"   {json.dumps(res, indent=2, default=str)}")
                
                # Provide specific debugging guidance
                log.warning("üîç IMMEDIATE DEBUGGING STEPS:")
                log.warning("   1. Check coordinator logs for routing decision")
                log.warning("   2. Verify OCPS_DRIFT_THRESHOLD environment variable")
                log.warning("   3. Check if fast-path organs are available")
                log.warning("   4. Look for forced escalation logic in coordinator code")
                    
            else:
                log.info("‚úÖ Fast path confirmed: direct routing (no HGNN plan)")
            
            # Log fast path characteristics
            fast_metadata = {k: v for k, v in res.items() if k in ["routed_to", "organ_id", "processing_time_ms", "type"]}
            if fast_metadata:
                log.info(f"üìã Fast path metadata: {fast_metadata}")
    else:
        log.warning("No DB connection; cannot verify fast-path completion in DB.")

    # Escalation
    esc_tid = scenario_escalation(conn)
    log.info(f"Escalation task_id = {esc_tid}")
    if conn:
        row = wait_for_completion(conn, esc_tid, "ESCALATION", timeout_s=150.0)
        
        # --- HGNN VALIDATION ---
        # Debug: inspect the database row structure
        log.info(f"üìã Database row keys: {list(row.keys())}")
        log.info(f"üìã Result column type: {type(row.get('result'))}")
        
        # Normalize result: ensure it's a dict
        raw_res = row.get("result")
        log.info(f"üìã Raw result type: {type(raw_res)}")
        
        res = normalize_result(raw_res)
        if not res:
            exit_if_strict("Escalation result could not be normalized to dict")
            log.error(f"Raw result: {raw_res}")
            return
        
        # Use consolidated plan detection helper
        has_plan, plan = detect_plan(res)
        
        if not has_plan or not plan:
            exit_if_strict("Escalation did NOT include HGNN decomposition plan")
            log.error(f"Available result keys: {list(res.keys())}")
            log.error(f"Result content: {res}")
            return
        
        # Validate plan structure
        if not isinstance(plan, list):
            exit_if_strict(f"Plan is not a list: {type(plan)}")
            return
        
        log.info(f"‚úÖ Escalation returned HGNN plan with {len(plan)} steps")
        
        # Check each step structure
        valid_steps = 0
        for i, step in enumerate(plan):
            if not isinstance(step, dict):
                log.error(f"‚ö†Ô∏è Step {i} is not a dictionary: {step}")
                continue
                
            # Check for required fields (organ_id is essential)
            if "organ_id" not in step:
                log.error(f"‚ö†Ô∏è Step {i} missing organ_id: {step}")
                continue
            
            # Log step details
            organ_id = step.get("organ_id")
            success = step.get("success", "unknown")
            
            # Check if step has task info (either direct or nested)
            if "task" in step:
                task_info = step["task"]
                if isinstance(task_info, dict):
                    task_type = task_info.get("type", "unknown")
                else:
                    task_type = str(task_info)
            elif "result" in step:
                # Handle case where result contains the task info
                result = step["result"]
                if isinstance(result, dict):
                    task_type = result.get("type", "unknown")
                    # Log more details about the result structure
                    log.info(f"      üìã Result keys: {list(result.keys())}")
                else:
                    task_type = str(result)
            else:
                task_type = "unknown"
            
            # Log step details with more context
            log.info(f"   Step {i} -> organ={organ_id} success={success} task={task_type}")
            
            # Show additional step fields for debugging
            step_fields = [k for k in step.keys() if k not in ["organ_id", "success", "task", "result"]]
            if step_fields:
                log.info(f"      üìã Additional fields: {step_fields}")
            
            valid_steps += 1
        
        if valid_steps == 0:
            exit_if_strict("No valid steps found in HGNN plan")
            return
        
        # Ensure we can tell it was escalated
        # Check multiple indicators of HGNN involvement
        escalated = (
            res.get("escalated") is True or 
            "plan" in res or 
            "solution_steps" in res or
            res.get("type") == "list_result" or  # New structured format
            (plan and len(plan) > 0)  # If we successfully parsed a plan, that proves HGNN was involved
        )
        
        if escalated:
            log.info("‚úÖ Escalation path confirmed (HGNN invoked)")
        else:
            exit_if_strict("Escalation result does not prove HGNN involvement")
            log.error(f"Plan found: {plan is not None}, Plan length: {len(plan) if plan else 0}")
            return
        
        # Log metadata for debugging
        metadata = {k: v for k, v in res.items() if k in ["escalated", "plan_source", "planner", "cognitive_core_version"]}
        if metadata:
            log.info(f"üìã Escalation metadata: {metadata}")
            
    else:
        log.warning("No DB connection; cannot verify escalation completion in DB.")

    # Optional: Graph task
    if env_bool("VERIFY_GRAPH_TASK", False):
        g_tid = scenario_graph_task(conn)
        if g_tid and conn:
            wait_for_completion(conn, g_tid, "GRAPH", timeout_s=150.0)

    # Snapshot coordinator metrics/status (best-effort)
    try:
        st = serve_deployment_status(coord)
        log.info(f"Coordinator final status snapshot: {json.dumps(st, indent=2, default=str)}")
    except Exception as e:
        log.warning(f"Coordinator status snapshot failed: {e}")

    # --- VALIDATION SUMMARY ---
    log.info("=" * 60)
    log.info("üéØ SEEDCORE ARCHITECTURE VALIDATION SUMMARY")
    log.info("=" * 60)
    log.info("‚úÖ Ray cluster & actors: HEALTHY")
    log.info("‚úÖ Serve apps: RUNNING")
    
    # Fast path summary - tie to actual results
    if conn:
        # Use the tracked result from validation
        if fast_path_has_plan:
            log.warning("‚ö†Ô∏è Fast path: BUG DETECTED (HGNN escalation)")
        else:
            log.info("‚úÖ Fast path: DIRECT ROUTING (no HGNN)")
        
        # Check for drift score mismatch
        try:
            fast_row = pg_get_task(conn, fast_tid)
            if fast_row:
                drift_score = fast_row.get("drift_score")
                threshold = env_float('OCPS_DRIFT_THRESHOLD', 0.5)
                if drift_score and drift_score >= threshold:
                    log.warning(f"‚ö†Ô∏è Fast path drift score {drift_score} >= threshold {threshold}")
                    log.warning("   This suggests incorrect routing - should have escalated")
        except Exception:
            pass  # Ignore errors in summary
        
        # Add warning if fast path contains HGNN steps
        if fast_path_has_plan:
            log.warning("‚ö†Ô∏è SUMMARY: Fast path incorrectly escalated to HGNN")
            log.warning("   This indicates a routing bug in the coordinator")
    else:
        log.warning("‚ö†Ô∏è Fast path: UNKNOWN (DB unavailable)")
        log.warning("   Set SEEDCORE_PG_DSN environment variable for full verification")
    
    # Escalation summary
    if conn:
        try:
            esc_row = pg_get_task(conn, esc_tid)
            if esc_row and esc_row.get("result"):
                esc_res = normalize_result(esc_row.get("result"))
                has_plan, plan_steps = detect_plan(esc_res)
                if has_plan and plan_steps:
                    log.info(f"‚úÖ Escalation: HGNN DECOMPOSITION ({len(plan_steps)} steps)")
                else:
                    log.warning("‚ö†Ô∏è Escalation: UNKNOWN (no plan detected)")
            else:
                log.warning("‚ö†Ô∏è Escalation: UNKNOWN (no result data)")
        except Exception as e:
            log.warning(f"‚ö†Ô∏è Escalation: UNKNOWN (error analyzing: {e})")
    else:
        log.warning("‚ö†Ô∏è Escalation: UNKNOWN (DB unavailable)")
        log.warning("   Set SEEDCORE_PG_DSN environment variable for full verification")
    
    log.info("‚úÖ Coordinator: RESPONSIVE")
    
    # Overall status
    if conn:
        log.info("=" * 60)
        if fast_path_has_plan:
            log.warning("‚ö†Ô∏è ROUTING BUG DETECTED: Fast path incorrectly escalated to HGNN")
            log.warning("   Check coordinator logs and OCPS_DRIFT_THRESHOLD configuration")
            log.warning("   This indicates a bug in the coordinator's routing logic")
        else:
            log.info("üéâ All validations passed! SeedCore architecture is working correctly.")
        log.info("=" * 60)
    else:
        log.warning("=" * 60)
        log.warning("‚ö†Ô∏è Validation incomplete - DB unavailable for result verification")
        log.warning("   Set SEEDCORE_PG_DSN environment variable for full verification")
        log.warning("=" * 60)

if __name__ == "__main__":
    main()

