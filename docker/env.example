# SeedCore Environment Configuration for Docker
# Copy this file to `.env` and edit values as needed for your environment.

# =============================================================================
# Database Configuration (Docker container names)
# =============================================================================

# PostgreSQL Data Source Name (DSN) for database connection
PG_DSN=postgresql://postgres:YOUR_PASSWORD@postgres:5432/postgres

# PostgreSQL Connection Pool Settings
POSTGRES_POOL_SIZE=20
POSTGRES_MAX_OVERFLOW=10
POSTGRES_POOL_TIMEOUT=30
POSTGRES_POOL_RECYCLE=1800
POSTGRES_POOL_PRE_PING=true

# MySQL configuration
MYSQL_DATABASE_URL=mysql+mysqlconnector://seedcore:password@seedcore-mysql:3306/seedcore

# MySQL Connection Pool Settings
MYSQL_POOL_SIZE=10
MYSQL_MAX_OVERFLOW=5
MYSQL_POOL_TIMEOUT=30
MYSQL_POOL_RECYCLE=1800
MYSQL_POOL_PRE_PING=true

# Neo4j configuration
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=YOUR_NEO4J_PASSWORD

# Neo4j Connection Pool Settings
NEO4J_POOL_SIZE=50
NEO4J_CONNECTION_ACQUISITION_TIMEOUT=30

# =============================================================================
# Ray Configuration (Docker container setup)
# =============================================================================

# Ray head node service name (Docker network)
RAY_HOST=ray-head
RAY_PORT=10001
RAY_ADDRESS=ray://ray-head:10001
RAY_NAMESPACE=seedcore
RAY_IGNORE_REINIT_ERROR=true
RAY_CONNECTION_TIMEOUT=30

# =============================================================================
# API Configuration
# =============================================================================

# The API root URL as seen from inside Docker (usually for other containers)
# Note: Use SEEDCORE_API_ADDRESS for internal container communication

# API server bind host and port
API_HOST=0.0.0.0
API_PORT=8002

# =============================================================================
# Development Configuration
# =============================================================================

# Set DEV_RELOAD=1 to enable hot-reload during local development
# Set to 0 or leave unset for production/stable operation
DEV_RELOAD=0

# =============================================================================
# Logging
# =============================================================================

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# Environment
# =============================================================================

# Set to "development" or "production"
ENVIRONMENT=development

# =============================================================================
# Ray Dashboard Configuration
# =============================================================================

# Public Grafana URL for Ray dashboard (used in browser iframes)
# Use http://localhost:3000 for local dev, or http://YOUR_PUBLIC_IP:3000 in production
PUBLIC_GRAFANA_URL=http://YOUR_PUBLIC_IP:3000

# =============================================================================
# Optional External Services (uncomment and set as needed)
# =============================================================================

# RAGFLOW_API_URL=http://localhost:9380
# CHROMA_HOST=localhost
# CHROMA_PORT=8000
# REDIS_URL=redis://localhost:6379/0

# =============================================================================
# LLM Configuration (OpenAI, Gemini, Claude, etc.)
# =============================================================================

# OpenAI API Key for GPT models
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE

# LLM Provider Configuration
# Supported providers: openai, anthropic, google, azure, local
LLM_PROVIDER=openai

# LLM Model Configuration
LLM_MODEL=gpt-4o
LLM_MAX_TOKENS=1024
LLM_TEMPERATURE=0.7
LLM_TOP_P=1.0
LLM_FREQUENCY_PENALTY=0.0
LLM_PRESENCE_PENALTY=0.0

# LLM API Configuration
LLM_API_BASE=
LLM_API_VERSION=
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0

# LLM Streaming Configuration
LLM_STREAM=false
LLM_STREAM_CHUNK_SIZE=1

# LLM Safety and Content Filtering
LLM_SAFE_MODE=false
LLM_CONTENT_FILTER=true

# LLM Rate Limiting
LLM_RATE_LIMIT_REQUESTS_PER_MINUTE=60
LLM_RATE_LIMIT_TOKENS_PER_MINUTE=150000

# LLM Caching Configuration
LLM_ENABLE_CACHING=true
LLM_CACHE_TTL=3600

# LLM Logging Configuration
LLM_LOG_REQUESTS=true
LLM_LOG_RESPONSES=false
LLM_LOG_TOKENS=true

# LLM Advanced Configuration
LLM_SYSTEM_PROMPT=
LLM_USER_PROMPT_TEMPLATE=